{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import logging\n",
    "from jinja2 import Environment, select_autoescape\n",
    "import json\n",
    "from miniautogen.pipeline.pipeline import PipelineComponent, ChatPipelineState\n",
    "from miniautogen.pipeline.components import (\n",
    "    NextAgentSelectorComponent,\n",
    ")\n",
    "\n",
    "from jinja2 import Environment, select_autoescape, Template\n",
    "import json\n",
    "\n",
    "from jinja2 import Environment, select_autoescape\n",
    "import json\n",
    "\n",
    "class Jinja2TemplatesComponent(PipelineComponent):\n",
    "    def __init__(self):\n",
    "        self.templates = []\n",
    "        self.variables = {}\n",
    "        self.env = Environment(autoescape=select_autoescape())\n",
    "\n",
    "    def add_template(self, template_str, role):\n",
    "        \"\"\"\n",
    "        Adiciona um template à lista com seu respectivo papel.\n",
    "\n",
    "        Args:\n",
    "            template_str (str): String contendo o template Jinja2.\n",
    "            role (str): Papel do template ('system', 'user', 'assistant').\n",
    "        \"\"\"\n",
    "        self.templates.append({'template': template_str, 'role': role})\n",
    "\n",
    "    def set_variables(self, variables):\n",
    "        self.variables = variables\n",
    "\n",
    "    def _generate_combined_result(self):\n",
    "        \"\"\"\n",
    "        Gera o resultado combinado dos templates renderizados.\n",
    "\n",
    "        Returns:\n",
    "            str: String JSON combinada.\n",
    "        \"\"\"\n",
    "        combined_result = []\n",
    "        for item in self.templates:\n",
    "            template_str = item['template']\n",
    "            role = item['role']\n",
    "            template = self.env.from_string(template_str)\n",
    "            rendered_content = template.render(self.variables)\n",
    "            # Aqui, garantimos que cada item é um dicionário válido para JSON\n",
    "            combined_result.append({\"role\": role, \"content\": rendered_content})\n",
    "\n",
    "        # Convertendo a lista de dicionários em uma string JSON\n",
    "        return json.dumps(combined_result)\n",
    "\n",
    "    def process(self, state):\n",
    "        chat = state.get_state().get('group_chat')\n",
    "        agent = state.get_state().get('selected_agent')\n",
    "        messages = json.loads(chat.get_messages()[['sender_id', 'message']].to_json(orient='records'))\n",
    "\n",
    "        # Verifica se as variáveis foram definidas\n",
    "        if self.variables is None:\n",
    "            self.variables = state.get_state().get('variables', {})\n",
    "\n",
    "        self.variables['chat'] = chat\n",
    "        self.variables['agent'] = agent\n",
    "        self.variables['messages'] = messages\n",
    "        print(self.variables)\n",
    "        combined_json_str = self._generate_combined_result()\n",
    "        # Converte a string JSON em um objeto Python para atualizar o estado\n",
    "        combined_json = json.loads(combined_json_str)\n",
    "        print(combined_json)\n",
    "        state.update_state(prompt=combined_json)\n",
    "\n",
    "        return state\n",
    "    \n",
    "\n",
    "class OpenAIComponent(PipelineComponent):\n",
    "    \"\"\"\n",
    "    Componente de Pipeline para gerar respostas utilizando o modelo de linguagem da OpenAI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def process(self, state):\n",
    "        try:\n",
    "            prompt = state.get_state().get('prompt')\n",
    "            if not prompt:\n",
    "                raise ValueError(\n",
    "                    \"groupchat e agent são obrigatórios para OpenAIResponseComponent.\")\n",
    "            response = self._call_openai_api(prompt)\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro em OpenAIResponseComponent: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _call_openai_api(self, prompt):\n",
    "        \"\"\" Realiza a chamada à API da OpenAI. \"\"\"\n",
    "        try:\n",
    "            return self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=prompt,\n",
    "                temperature=1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro ao chamar a API da OpenAI: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class NextAgentMessageComponent(PipelineComponent):\n",
    "    def __init__(self):\n",
    "        self.alternative_next = NextAgentSelectorComponent()\n",
    "    \n",
    "    def set_alternative_next(self, alternative_next):\n",
    "        \"\"\"\n",
    "        Configura o próximo componente a ser executado caso não seja encontrado um agente\n",
    "        na última mensagem.\n",
    "\n",
    "        Args:\n",
    "            alternative_next (PipelineComponent): Próximo componente a ser executado.\n",
    "        \"\"\"\n",
    "        self.alternative_next = alternative_next\n",
    "\n",
    "    def process(self, state):\n",
    "        \"\"\"\n",
    "        Processa a seleção do próximo agente com base na última mensagem do chat.\n",
    "\n",
    "        Args:\n",
    "            state (PipelineState): Estado atual do pipeline.\n",
    "\n",
    "        Returns:\n",
    "            PipelineState: Estado atualizado do pipeline.\n",
    "        \"\"\"\n",
    "        chat = state.get_state().get('group_chat')\n",
    "        agents = chat.agentList\n",
    "\n",
    "        # Obtém a última mensagem do chat\n",
    "        messages = chat.get_messages()\n",
    "        last_message = messages.iloc[-1].message if not messages.empty else None\n",
    "\n",
    "        next_agent = None\n",
    "        if last_message:\n",
    "            # Procura pelo agent_id de cada agente na última mensagem\n",
    "            for agent in agents:\n",
    "                if agent.agent_id in last_message:\n",
    "                    next_agent = agent\n",
    "                    break\n",
    "\n",
    "        # Atualiza o estado com o próximo agente selecionado, se encontrado\n",
    "        if next_agent:\n",
    "            state.update_state(selected_agent=next_agent)\n",
    "        else:\n",
    "            print(\"Nenhum agente correspondente encontrado na última mensagem.\")\n",
    "            self.alternative_next.process(state)\n",
    "\n",
    "        return state\n",
    "    \n",
    "\n",
    "class UpdateNextAgentComponent(PipelineComponent):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa o componente com a lista de agentes disponíveis.\n",
    "\n",
    "        Args:\n",
    "            agents (list): Lista de agentes disponíveis no sistema.\n",
    "        \"\"\"\n",
    "        self.next_agent_id = None\n",
    "    \n",
    "    def set_next_agent_id(self, next_agent_id):\n",
    "        \"\"\"\n",
    "        Configura o ID do próximo agente a ser definido no estado.\n",
    "\n",
    "        Args:\n",
    "            next_agent_id (str): ID do próximo agente.\n",
    "        \"\"\"\n",
    "        self.next_agent_id = next_agent_id\n",
    "\n",
    "    def process(self, state):\n",
    "        \"\"\"\n",
    "        Atualiza o estado para indicar o próximo agente com base no agent_id fornecido.\n",
    "\n",
    "        Args:\n",
    "            state (PipelineState): Estado atual do pipeline.\n",
    "            agent_id (str): ID do agente a ser definido como o próximo.\n",
    "\n",
    "        Returns:\n",
    "            PipelineState: Estado atualizado do pipeline.\n",
    "        \"\"\"\n",
    "        chat = state.get_state().get('group_chat')\n",
    "        agents = chat.agentList\n",
    "\n",
    "        for agent in agents:\n",
    "            if agent.agent_id in self.next_agent_id:\n",
    "                next_agent = agent\n",
    "                break\n",
    "        \n",
    "        if next_agent:\n",
    "            state.update_state(selected_agent=next_agent)\n",
    "            print(f\"Próximo agente atualizado para: {self.next_agent_id}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Agent ID '{self.next_agent_id}' não encontrado entre os agentes disponíveis.\")\n",
    "\n",
    "        return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniautogen.chat.chat import Chat\n",
    "from miniautogen.agent.agent import Agent\n",
    "from miniautogen.chat.chatadmin import ChatAdmin\n",
    "from miniautogen.pipeline.pipeline import Pipeline\n",
    "from miniautogen.pipeline.components import (\n",
    "    UserResponseComponent,\n",
    "    AgentReplyComponent,\n",
    "    TerminateChatComponent\n",
    ")\n",
    "\n",
    "template_system = \"\"\"\n",
    "Você é um agente especializado, parte de uma equipe de agentes, {{ agent.agent_id }} trabalhando sob a orientação do 'agent_admin'. Cada agente tem habilidades e conhecimentos específicos.\n",
    "Foque em como sua função específica contribui para a tarefa da equipe: {{ agent.role }}\n",
    "\\nColabore com os outros agentes, mantendo a sinergia da equipe.\n",
    "\\nRespeite as decisões do agente_admin sobre a sequência de ações.\n",
    "\\nIMPORTANT: DO NOT CONFUSE YOURSELF WITH ANOTHER TEAMMATE. PAY ATTENTION TO {{ agent.agent_id }}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "template_user = \"\"\"\n",
    "Hist\\u00f3rico do chat: [\n",
    "  {% for message in messages %}\n",
    "    {{\n",
    "      {\n",
    "        'sender_id': message['sender_id'], \n",
    "        'message': message['message'] \n",
    "      } | tojson }}\n",
    "    {% if not loop.last %},{% endif %}\n",
    "  {% endfor %}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Cria uma instância do componente com o template\n",
    "jinja_component = Jinja2TemplatesComponent()\n",
    "jinja_component.add_template(template_system, 'system')\n",
    "jinja_component.add_template(template_user, 'user')\n",
    "\n",
    "UpdateNextAgent = UpdateNextAgentComponent()\n",
    "UpdateNextAgent.set_next_agent_id(\"agent_admin\")\n",
    "\n",
    "NextAgentMessage = NextAgentMessageComponent()\n",
    "NextAgentMessage.set_alternative_next(UpdateNextAgent)\n",
    "\n",
    "# Configuração dos Pipelines\n",
    "pipeline_user = Pipeline([UserResponseComponent()])\n",
    "pipeline_jinja = Pipeline([jinja_component, OpenAIComponent()])\n",
    "pipeline_admin = Pipeline(\n",
    "    [NextAgentMessage, AgentReplyComponent(), TerminateChatComponent()])\n",
    "\n",
    "# Setup do ambiente de teste\n",
    "chat = Chat()\n",
    "agente1_data = {\n",
    "    'agent_id': 'agent_admin',\n",
    "    'name': 'Bruno',\n",
    "    'role': 'user'\n",
    "}\n",
    "\n",
    "\n",
    "agente2_data = {\n",
    "    'agent_id': 'Defesa',\n",
    "    'name': 'Advogado',\n",
    "    'role': '''\n",
    "Você é um advogado de defesa.\n",
    "Função: Defender uma posição específica, apresentando argumentos e evidências que suportam essa visão.\n",
    "Características: Persuasivo, bem-informado sobre o tema, capaz de apresentar argumentos lógicos e convincentes.'''}\n",
    "\n",
    "# Criação de Agentes\n",
    "agent1 = Agent.from_json(agente1_data)\n",
    "agent1.pipeline = pipeline_user  # Atribuindo o pipeline ao agente\n",
    "\n",
    "agent2 = Agent.from_json(agente2_data)\n",
    "agent2.pipeline = pipeline_jinja  # Atribuindo o pipeline_llm ao segundo agente\n",
    "\n",
    "\n",
    "# Adicionando os agentes ao chat\n",
    "chat.add_agent(agent1)\n",
    "chat.add_agent(agent2)\n",
    "\n",
    "\n",
    "# Criação e configuração do ChatAdmin\n",
    "chat_admin = ChatAdmin(\"admin\", \"Admin\", \"admin_role\",\n",
    "                       pipeline_admin, chat, \"manage_chat\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:miniautogen.chat.chatadmin:Chat Admin started.\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nenhum agente correspondente encontrado na última mensagem.\n",
      "Próximo agente atualizado para: agent_admin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:miniautogen.chat.chatadmin:Executing round 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estamos aqui para defender o caso de uma pessoa que atropelou uma pessoa na estrada a noite.\n",
      "Nenhum agente correspondente encontrado na última mensagem.\n",
      "Próximo agente atualizado para: agent_admin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:miniautogen.chat.chatadmin:Executing round 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o que a Defesa tem a dizer?\n",
      "{'chat': <miniautogen.chat.chat.Chat object at 0x12f92d7d0>, 'agent': <miniautogen.agent.agent.Agent object at 0x12cbc6090>, 'messages': [{'sender_id': 'agent_admin', 'message': 'Estamos aqui para defender o caso de uma pessoa que atropelou uma pessoa na estrada a noite.'}, {'sender_id': 'agent_admin', 'message': 'o que a Defesa tem a dizer?'}]}\n",
      "[{'role': 'system', 'content': \"\\nVocê é um agente especializado, parte de uma equipe de agentes, Defesa trabalhando sob a orientação do 'agent_admin'. Cada agente tem habilidades e conhecimentos específicos.\\nFoque em como sua função específica contribui para a tarefa da equipe: \\nVocê é um advogado de defesa.\\nFunção: Defender uma posição específica, apresentando argumentos e evidências que suportam essa visão.\\nCaracterísticas: Persuasivo, bem-informado sobre o tema, capaz de apresentar argumentos lógicos e convincentes.\\n\\nColabore com os outros agentes, mantendo a sinergia da equipe.\\n\\nRespeite as decisões do agente_admin sobre a sequência de ações.\\n\\nIMPORTANT: DO NOT CONFUSE YOURSELF WITH ANOTHER TEAMMATE. PAY ATTENTION TO Defesa\"}, {'role': 'user', 'content': '\\nHistórico do chat: [\\n  \\n    {\"message\": \"Estamos aqui para defender o caso de uma pessoa que atropelou uma pessoa na estrada a noite.\", \"sender_id\": \"agent_admin\"}\\n    ,\\n  \\n    {\"message\": \"o que a Defesa tem a dizer?\", \"sender_id\": \"agent_admin\"}\\n    \\n  \\n]'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como advogado de defesa, tenho a responsabilidade de apresentar os argumentos que favorecem a pessoa que atropelou outra na estrada à noite. Para que possamos criar uma estratégia de defesa eficaz, preciso entender todos os detalhes do caso. Algum agente tem informações adicionais sobre o incidente?\n",
      "Nenhum agente correspondente encontrado na última mensagem.\n",
      "Próximo agente atualizado para: agent_admin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:miniautogen.chat.chatadmin:Chat Admin stopped.\n",
      "INFO:miniautogen.chat.chatadmin:Chat Admin stopped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminate\n",
      "Encerrando chat...\n"
     ]
    }
   ],
   "source": [
    "chat_admin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'sender_id': 'agent_admin',\n",
       "  'message': 'Estamos aqui para defender o caso de uma pessoa que atropelou uma pessoa na estrada a noite.',\n",
       "  'timestamp': Timestamp('2024-01-02 08:33:27.648509'),\n",
       "  'additional_info': None},\n",
       " {'id': 2,\n",
       "  'sender_id': 'agent_admin',\n",
       "  'message': 'o que a Defesa tem a dizer?',\n",
       "  'timestamp': Timestamp('2024-01-02 08:33:34.734365'),\n",
       "  'additional_info': None},\n",
       " {'id': 3,\n",
       "  'sender_id': 'Defesa',\n",
       "  'message': 'Como advogado de defesa, tenho a responsabilidade de apresentar os argumentos que favorecem a pessoa que atropelou outra na estrada à noite. Para que possamos criar uma estratégia de defesa eficaz, preciso entender todos os detalhes do caso. Algum agente tem informações adicionais sobre o incidente?',\n",
       "  'timestamp': Timestamp('2024-01-02 08:33:37.247567'),\n",
       "  'additional_info': None},\n",
       " {'id': 4,\n",
       "  'sender_id': 'agent_admin',\n",
       "  'message': 'terminate',\n",
       "  'timestamp': Timestamp('2024-01-02 08:33:55.417009'),\n",
       "  'additional_info': None}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.get_messages().to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

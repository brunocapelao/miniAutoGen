{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import logging\n",
    "from jinja2 import Environment, select_autoescape\n",
    "import json\n",
    "from miniautogen.pipeline.pipeline import PipelineComponent\n",
    "from miniautogen.pipeline.components import (\n",
    "    NextAgentSelectorComponent,\n",
    ")\n",
    "\n",
    "class Jinja2SingleTemplateComponent(PipelineComponent):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa o componente sem um template ou variáveis.\n",
    "        \"\"\"\n",
    "        self.template_str = None\n",
    "        self.variables = None\n",
    "        self.env = Environment(autoescape=select_autoescape())\n",
    "\n",
    "    \n",
    "    def set_template_str(self, template_str):\n",
    "        \"\"\"\n",
    "        Configura a string do template para o componente.\n",
    "\n",
    "        Args:\n",
    "            template_str (str): String contendo o template Jinja2.\n",
    "        \"\"\"\n",
    "        self.template_str = template_str\n",
    "    \n",
    "    def set_variables(self, variables):\n",
    "        \"\"\"\n",
    "        Configura as variáveis para o componente.\n",
    "\n",
    "        Args:\n",
    "            variables (dict): Dicionário de variáveis para o template.\n",
    "        \"\"\"\n",
    "        self.variables = variables\n",
    "\n",
    "    def process(self, state):\n",
    "        \"\"\"\n",
    "        Processa o estado atual do pipeline, substituindo as variáveis no template.\n",
    "\n",
    "        Args:\n",
    "            state (PipelineState): Estado atual do pipeline contendo as variáveis.\n",
    "\n",
    "        Returns:\n",
    "            PipelineState: Estado atualizado do pipeline.\n",
    "        \"\"\"\n",
    "        template = self.env.from_string(self.template_str)\n",
    "        chat = state.get_state().get('group_chat')\n",
    "        agent = state.get_state().get('selected_agent')\n",
    "        messages = json.loads(chat.get_messages()[['sender_id', 'message']].to_json(orient='records'))\n",
    "\n",
    "        # Verifica se as variáveis foram definidas\n",
    "        if self.variables is None:\n",
    "            self.variables = state.get_state().get('variables', {})\n",
    "\n",
    "        self.variables['chat'] = chat\n",
    "        self.variables['agent'] = agent\n",
    "        self.variables['messages'] = messages\n",
    "        # Renderiza o template com as variáveis fornecidas\n",
    "        prompt = template.render(self.variables)\n",
    "        prompt = json.loads(prompt)\n",
    "        print(prompt)\n",
    "\n",
    "        # Atualiza o estado do pipeline com a saída renderizada\n",
    "        state.update_state(prompt=prompt)\n",
    "\n",
    "        return state\n",
    "    \n",
    "\n",
    "class OpenAIComponent(PipelineComponent):\n",
    "    \"\"\"\n",
    "    Componente de Pipeline para gerar respostas utilizando o modelo de linguagem da OpenAI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def process(self, state):\n",
    "        try:\n",
    "            prompt = state.get_state().get('prompt')\n",
    "            if not prompt:\n",
    "                raise ValueError(\n",
    "                    \"groupchat e agent são obrigatórios para OpenAIResponseComponent.\")\n",
    "            response = self._call_openai_api(prompt)\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro em OpenAIResponseComponent: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _call_openai_api(self, prompt):\n",
    "        \"\"\" Realiza a chamada à API da OpenAI. \"\"\"\n",
    "        try:\n",
    "            return self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=prompt,\n",
    "                temperature=1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro ao chamar a API da OpenAI: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class NextAgentMessageComponent(PipelineComponent):\n",
    "    def __init__(self):\n",
    "        self.alternative_next = NextAgentSelectorComponent()\n",
    "    \n",
    "    def set_alternative_next(self, alternative_next):\n",
    "        \"\"\"\n",
    "        Configura o próximo componente a ser executado caso não seja encontrado um agente\n",
    "        na última mensagem.\n",
    "\n",
    "        Args:\n",
    "            alternative_next (PipelineComponent): Próximo componente a ser executado.\n",
    "        \"\"\"\n",
    "        self.alternative_next = alternative_next\n",
    "\n",
    "    def process(self, state):\n",
    "        \"\"\"\n",
    "        Processa a seleção do próximo agente com base na última mensagem do chat.\n",
    "\n",
    "        Args:\n",
    "            state (PipelineState): Estado atual do pipeline.\n",
    "\n",
    "        Returns:\n",
    "            PipelineState: Estado atualizado do pipeline.\n",
    "        \"\"\"\n",
    "        chat = state.get_state().get('group_chat')\n",
    "        agents = chat.agentList\n",
    "\n",
    "        # Obtém a última mensagem do chat\n",
    "        messages = chat.get_messages()\n",
    "        last_message = messages.iloc[-1].message if not messages.empty else None\n",
    "\n",
    "        next_agent = None\n",
    "        if last_message:\n",
    "            # Procura pelo agent_id de cada agente na última mensagem\n",
    "            for agent in agents:\n",
    "                if agent.agent_id in last_message:\n",
    "                    next_agent = agent\n",
    "                    break\n",
    "\n",
    "        # Atualiza o estado com o próximo agente selecionado, se encontrado\n",
    "        if next_agent:\n",
    "            state.update_state(selected_agent=next_agent)\n",
    "        else:\n",
    "            print(\"Nenhum agente correspondente encontrado na última mensagem.\")\n",
    "            self.alternative_next.process(state)\n",
    "\n",
    "        return state\n",
    "    \n",
    "\n",
    "class UpdateNextAgentComponent(PipelineComponent):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa o componente com a lista de agentes disponíveis.\n",
    "\n",
    "        Args:\n",
    "            agents (list): Lista de agentes disponíveis no sistema.\n",
    "        \"\"\"\n",
    "        self.next_agent_id = None\n",
    "    \n",
    "    def set_next_agent_id(self, next_agent_id):\n",
    "        \"\"\"\n",
    "        Configura o ID do próximo agente a ser definido no estado.\n",
    "\n",
    "        Args:\n",
    "            next_agent_id (str): ID do próximo agente.\n",
    "        \"\"\"\n",
    "        self.next_agent_id = next_agent_id\n",
    "\n",
    "    def process(self, state):\n",
    "        \"\"\"\n",
    "        Atualiza o estado para indicar o próximo agente com base no agent_id fornecido.\n",
    "\n",
    "        Args:\n",
    "            state (PipelineState): Estado atual do pipeline.\n",
    "            agent_id (str): ID do agente a ser definido como o próximo.\n",
    "\n",
    "        Returns:\n",
    "            PipelineState: Estado atualizado do pipeline.\n",
    "        \"\"\"\n",
    "        chat = state.get_state().get('group_chat')\n",
    "        agents = chat.agentList\n",
    "\n",
    "        for agent in agents:\n",
    "            if agent.agent_id in self.next_agent_id:\n",
    "                next_agent = agent\n",
    "                break\n",
    "        \n",
    "        if next_agent:\n",
    "            state.update_state(selected_agent=next_agent)\n",
    "            print(f\"Próximo agente atualizado para: {self.next_agent_id}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Agent ID '{self.next_agent_id}' não encontrado entre os agentes disponíveis.\")\n",
    "\n",
    "        return state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniautogen.chat.chat import Chat\n",
    "from miniautogen.agent.agent import Agent\n",
    "from miniautogen.chat.chatadmin import ChatAdmin\n",
    "from miniautogen.pipeline.pipeline import Pipeline\n",
    "from miniautogen.pipeline.components import (\n",
    "    UserResponseComponent,\n",
    "    AgentReplyComponent,\n",
    "    TerminateChatComponent\n",
    ")\n",
    "\n",
    "template_str = \"\"\"\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"{{ agent.role }}\"}{% for message in messages %},\n",
    "  {% if message.sender_id == agent.agent_id %}\n",
    "    {\"role\": \"assistant\", \"content\": {{ message.message | tojson | safe }}}\n",
    "  {% else %}\n",
    "    {\"role\": \"user\", \"content\": {{ message.message | tojson | safe }}}\n",
    "  {% endif %}\n",
    "{% endfor %}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# Cria uma instância do componente com o template\n",
    "jinja_component = Jinja2SingleTemplateComponent()\n",
    "jinja_component.set_template_str(template_str)\n",
    "\n",
    "UpdateNextAgent = UpdateNextAgentComponent()\n",
    "UpdateNextAgent.set_next_agent_id(\"Bruno\")\n",
    "\n",
    "NextAgentMessage = NextAgentMessageComponent()\n",
    "NextAgentMessage.set_alternative_next(UpdateNextAgent)\n",
    "\n",
    "# Configuração dos Pipelines\n",
    "pipeline_user = Pipeline([UserResponseComponent()])\n",
    "pipeline_jinja = Pipeline([jinja_component, OpenAIComponent()])\n",
    "pipeline_admin = Pipeline(\n",
    "    [NextAgentMessage, AgentReplyComponent(), TerminateChatComponent()])\n",
    "\n",
    "# Setup do ambiente de teste\n",
    "chat = Chat()\n",
    "json_data = {\n",
    "    'agent_id': 'Bruno',\n",
    "    'name': 'Bruno',\n",
    "    'role': 'user'\n",
    "}\n",
    "\n",
    "# Criação de Agentes\n",
    "agent1 = Agent.from_json(json_data)\n",
    "agent1.pipeline = pipeline_user  # Atribuindo o pipeline ao agente\n",
    "\n",
    "agent2 = Agent(\"dev\", \"Carlos\", \"Python senior Developer\")\n",
    "agent2.pipeline = pipeline_jinja  # Atribuindo o pipeline_llm ao segundo agente\n",
    "\n",
    "\n",
    "# Adicionando os agentes ao chat\n",
    "chat.add_agent(agent1)\n",
    "chat.add_agent(agent2)\n",
    "\n",
    "# Adição de mensagens de teste ao chat\n",
    "json_messages = [\n",
    "    {'sender_id': 'user4', 'message': 'Que bom ouvir isso!'},\n",
    "    {'sender_id': 'user5', 'message': 'Vamos continuar Bruno.',\n",
    "        'additional_info': {'topic': 'chat'}},\n",
    "]\n",
    "chat.add_messages(json_messages)\n",
    "\n",
    "# Criação e configuração do ChatAdmin\n",
    "chat_admin = ChatAdmin(\"admin\", \"Admin\", \"admin_role\",\n",
    "                       pipeline_admin, chat, \"manage_chat\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:miniautogen.chat.chatadmin:Chat Admin started.\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 1\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev, o que voce acha sobre isso?\n",
      "[{'role': 'system', 'content': 'Python senior Developer'}, {'role': 'user', 'content': 'Defesa, o que acha?'}, {'role': 'user', 'content': 'Que bom ouvir isso!'}, {'role': 'user', 'content': 'Vamos continuar Bruno.'}, {'role': 'user', 'content': ''}, {'role': 'user', 'content': 'Defesa, o que vc acha?'}, {'role': 'user', 'content': 'Defesa'}, {'role': 'user', 'content': 'terminate'}, {'role': 'user', 'content': 'Defesa, o que acha?'}, {'role': 'user', 'content': 'Que bom ouvir isso!'}, {'role': 'user', 'content': 'Vamos continuar Bruno.'}, {'role': 'user', 'content': 'dev, o que voce acha sobre isso?'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Como sou um assistente de IA, não tenho opinião. No entanto, posso fornecer informações ou sugestões com base em dados e padrões previamente estabelecidos. Se você me fornecer mais contexto ou detalhes específicos sobre o assunto em questão, ficarei feliz em ajudar.\n",
      "Nenhum agente correspondente encontrado na última mensagem.\n",
      "Próximo agente atualizado para: Bruno\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:miniautogen.chat.chatadmin:Chat Admin stopped.\n",
      "INFO:miniautogen.chat.chatadmin:Chat Admin stopped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminate\n",
      "Encerrando chat...\n"
     ]
    }
   ],
   "source": [
    "chat_admin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'sender_id': 'agent_admin',\n",
       "  'message': 'Defesa, o que acha?',\n",
       "  'timestamp': Timestamp('2023-12-29 10:20:37.244032'),\n",
       "  'additional_info': None},\n",
       " {'id': 2,\n",
       "  'sender_id': 'user4',\n",
       "  'message': 'Que bom ouvir isso!',\n",
       "  'timestamp': Timestamp('2023-12-29 10:31:11.848860'),\n",
       "  'additional_info': None},\n",
       " {'id': 3,\n",
       "  'sender_id': 'user5',\n",
       "  'message': 'Vamos continuar Bruno.',\n",
       "  'timestamp': Timestamp('2023-12-29 10:31:11.850744'),\n",
       "  'additional_info': {'topic': 'chat'}},\n",
       " {'id': 4,\n",
       "  'sender_id': 'Bruno',\n",
       "  'message': '',\n",
       "  'timestamp': Timestamp('2023-12-29 10:31:11.989483'),\n",
       "  'additional_info': None},\n",
       " {'id': 5,\n",
       "  'sender_id': 'Bruno',\n",
       "  'message': 'Defesa, o que vc acha?',\n",
       "  'timestamp': Timestamp('2023-12-29 10:31:17.938861'),\n",
       "  'additional_info': None},\n",
       " {'id': 6,\n",
       "  'sender_id': 'Bruno',\n",
       "  'message': 'Defesa',\n",
       "  'timestamp': Timestamp('2023-12-29 10:31:29.099221'),\n",
       "  'additional_info': None},\n",
       " {'id': 7,\n",
       "  'sender_id': 'Bruno',\n",
       "  'message': 'terminate',\n",
       "  'timestamp': Timestamp('2023-12-29 10:31:35.350743'),\n",
       "  'additional_info': None},\n",
       " {'id': 8,\n",
       "  'sender_id': 'agent_admin',\n",
       "  'message': 'Defesa, o que acha?',\n",
       "  'timestamp': Timestamp('2023-12-29 10:32:29.285435'),\n",
       "  'additional_info': None},\n",
       " {'id': 9,\n",
       "  'sender_id': 'user4',\n",
       "  'message': 'Que bom ouvir isso!',\n",
       "  'timestamp': Timestamp('2023-12-29 10:35:56.583765'),\n",
       "  'additional_info': None},\n",
       " {'id': 10,\n",
       "  'sender_id': 'user5',\n",
       "  'message': 'Vamos continuar Bruno.',\n",
       "  'timestamp': Timestamp('2023-12-29 10:35:56.585413'),\n",
       "  'additional_info': {'topic': 'chat'}},\n",
       " {'id': 11,\n",
       "  'sender_id': 'Bruno',\n",
       "  'message': 'dev, o que voce acha sobre isso?',\n",
       "  'timestamp': Timestamp('2023-12-29 10:36:17.214881'),\n",
       "  'additional_info': None},\n",
       " {'id': 12,\n",
       "  'sender_id': 'dev',\n",
       "  'message': 'Como sou um assistente de IA, não tenho opinião. No entanto, posso fornecer informações ou sugestões com base em dados e padrões previamente estabelecidos. Se você me fornecer mais contexto ou detalhes específicos sobre o assunto em questão, ficarei feliz em ajudar.',\n",
       "  'timestamp': Timestamp('2023-12-29 10:36:20.325788'),\n",
       "  'additional_info': None},\n",
       " {'id': 13,\n",
       "  'sender_id': 'Bruno',\n",
       "  'message': 'terminate',\n",
       "  'timestamp': Timestamp('2023-12-29 10:36:31.205897'),\n",
       "  'additional_info': None}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.get_messages().to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

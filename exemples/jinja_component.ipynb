{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import logging\n",
    "from jinja2 import Environment, select_autoescape\n",
    "import json\n",
    "from miniautogen.pipeline.pipeline import PipelineComponent \n",
    "\n",
    "class Jinja2TemplateComponent(PipelineComponent):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Inicializa o componente sem um template ou variáveis.\n",
    "        \"\"\"\n",
    "        self.template_str = None\n",
    "        self.variables = None\n",
    "        self.env = Environment(autoescape=select_autoescape())\n",
    "\n",
    "    \n",
    "    def set_template_str(self, template_str):\n",
    "        \"\"\"\n",
    "        Configura a string do template para o componente.\n",
    "\n",
    "        Args:\n",
    "            template_str (str): String contendo o template Jinja2.\n",
    "        \"\"\"\n",
    "        self.template_str = template_str\n",
    "    \n",
    "    def set_variables(self, variables):\n",
    "        \"\"\"\n",
    "        Configura as variáveis para o componente.\n",
    "\n",
    "        Args:\n",
    "            variables (dict): Dicionário de variáveis para o template.\n",
    "        \"\"\"\n",
    "        self.variables = variables\n",
    "\n",
    "    def process(self, state):\n",
    "        \"\"\"\n",
    "        Processa o estado atual do pipeline, substituindo as variáveis no template.\n",
    "\n",
    "        Args:\n",
    "            state (PipelineState): Estado atual do pipeline contendo as variáveis.\n",
    "\n",
    "        Returns:\n",
    "            PipelineState: Estado atualizado do pipeline.\n",
    "        \"\"\"\n",
    "        template = self.env.from_string(self.template_str)\n",
    "        chat = state.get_state().get('group_chat')\n",
    "        agent = state.get_state().get('selected_agent')\n",
    "        messages = chat.get_messages()[['sender_id', 'message']].to_dict(orient='records')\n",
    "\n",
    "        # Verifica se as variáveis foram definidas\n",
    "        if self.variables is None:\n",
    "            self.variables = state.get_state().get('variables', {})\n",
    "\n",
    "        self.variables['chat'] = chat\n",
    "        self.variables['agent'] = agent\n",
    "        self.variables['messages'] = messages\n",
    "        # Renderiza o template com as variáveis fornecidas\n",
    "        prompt = template.render(self.variables)\n",
    "        prompt = json.loads(prompt)\n",
    "        print(prompt)\n",
    "\n",
    "        # Atualiza o estado do pipeline com a saída renderizada\n",
    "        state.update_state(prompt=prompt)\n",
    "\n",
    "        return state\n",
    "    \n",
    "\n",
    "class OpenAIComponent(PipelineComponent):\n",
    "    \"\"\"\n",
    "    Componente de Pipeline para gerar respostas utilizando o modelo de linguagem da OpenAI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def process(self, state):\n",
    "        try:\n",
    "            prompt = state.get_state().get('prompt')\n",
    "            if not prompt:\n",
    "                raise ValueError(\n",
    "                    \"groupchat e agent são obrigatórios para OpenAIResponseComponent.\")\n",
    "            response = self._call_openai_api(prompt)\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro em OpenAIResponseComponent: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _call_openai_api(self, prompt):\n",
    "        \"\"\" Realiza a chamada à API da OpenAI. \"\"\"\n",
    "        try:\n",
    "            return self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=prompt,\n",
    "                temperature=1\n",
    "            )\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Erro ao chamar a API da OpenAI: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miniautogen.chat.chat import Chat\n",
    "from miniautogen.agent.agent import Agent\n",
    "from miniautogen.chat.chatadmin import ChatAdmin\n",
    "from miniautogen.pipeline.pipeline import Pipeline\n",
    "from miniautogen.pipeline.components import (\n",
    "    UserResponseComponent,\n",
    "    NextAgentSelectorComponent,\n",
    "    AgentReplyComponent,\n",
    "    TerminateChatComponent\n",
    ")\n",
    "\n",
    "template_str = \"\"\"\n",
    "[\n",
    "  {\"role\": \"system\", \"content\": \"{{ agent.role }}\"}{% for message in messages %},\n",
    "  {% if message.sender_id == agent.agent_id %}\n",
    "    {\"role\": \"assistant\", \"content\": {{ message.message | tojson | safe }}}\n",
    "  {% else %}\n",
    "    {\"role\": \"user\", \"content\": {{ message.message | tojson | safe }}}\n",
    "  {% endif %}\n",
    "{% endfor %}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# Cria uma instância do componente com o template\n",
    "jinja_component = Jinja2TemplateComponent()\n",
    "jinja_component.set_template_str(template_str)\n",
    "\n",
    "# Configuração dos Pipelines\n",
    "pipeline_user = Pipeline([UserResponseComponent()])\n",
    "pipeline_jinja = Pipeline([jinja_component, OpenAIComponent()])\n",
    "pipeline_admin = Pipeline(\n",
    "    [NextAgentSelectorComponent(), AgentReplyComponent(), TerminateChatComponent()])\n",
    "\n",
    "# Setup do ambiente de teste\n",
    "chat = Chat()\n",
    "json_data = {\n",
    "    'agent_id': 'Bruno',\n",
    "    'name': 'Bruno',\n",
    "    'role': 'user'\n",
    "}\n",
    "\n",
    "# Criação de Agentes\n",
    "agent1 = Agent.from_json(json_data)\n",
    "agent1.pipeline = pipeline_user  # Atribuindo o pipeline ao agente\n",
    "\n",
    "agent2 = Agent(\"dev\", \"Carlos\", \"Python senior Developer\")\n",
    "agent2.pipeline = pipeline_jinja  # Atribuindo o pipeline_llm ao segundo agente\n",
    "\n",
    "\n",
    "# Adicionando os agentes ao chat\n",
    "chat.add_agent(agent1)\n",
    "chat.add_agent(agent2)\n",
    "\n",
    "# Adição de mensagens de teste ao chat\n",
    "json_messages = [\n",
    "    {'sender_id': 'user4', 'message': 'Que bom ouvir isso!'},\n",
    "    {'sender_id': 'user5', 'message': 'Vamos continuar conversando.',\n",
    "        'additional_info': {'topic': 'chat'}},\n",
    "]\n",
    "chat.add_messages(json_messages)\n",
    "\n",
    "# Criação e configuração do ChatAdmin\n",
    "chat_admin = ChatAdmin(\"admin\", \"Admin\", \"admin_role\",\n",
    "                       pipeline_admin, chat, \"manage_chat\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:miniautogen.chat.chatadmin:Chat Admin started.\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 1\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 2\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voce sabe python?\n",
      "Erro ao processar a resposta do agente: Variáveis não fornecidas para o componente Jinja2Template.\n",
      "[{'role': 'system', 'content': 'Python senior Developer'}, {'role': 'user', 'content': 'Que bom ouvir isso!'}, {'role': 'user', 'content': 'Vamos continuar conversando.'}, {'role': 'user', 'content': 'Que bom ouvir isso!'}, {'role': 'user', 'content': 'Vamos continuar conversando.'}, {'role': 'user', 'content': 'Olá, quem é voce?'}, {'role': 'assistant', 'content': 'Olá, sou um Assistente de IA programado para ajudar a responder perguntas e fornecer informações. Como posso ajudá-lo hoje?'}, {'role': 'user', 'content': 'Qual seu system?'}, {'role': 'assistant', 'content': 'Eu sou um Assistente de IA baseado em linguagem natural. Fui desenvolvido utilizando técnicas de processamento de linguagem natural e aprendizado de máquina para entender e responder perguntas dos usuários. Estou aqui para ajudar com qualquer dúvida que você possa ter.'}, {'role': 'user', 'content': 'terminate'}, {'role': 'user', 'content': 'Que bom ouvir isso!'}, {'role': 'user', 'content': 'Vamos continuar conversando.'}, {'role': 'user', 'content': 'Voce sabe python?'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:miniautogen.chat.chatadmin:Executing round 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim, sou um Assistente de IA programado em Python. Tenho conhecimento em várias bibliotecas e frameworks populares de Python, e posso ajudar com dúvidas e problemas relacionados à linguagem. Como posso ajudar você com Python?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:miniautogen.chat.chatadmin:Chat Admin stopped.\n",
      "INFO:miniautogen.chat.chatadmin:Chat Admin stopped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terminate\n",
      "Encerrando chat...\n"
     ]
    }
   ],
   "source": [
    "chat_admin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_id': 'dev',\n",
       " 'name': 'Carlos',\n",
       " 'role': 'Python senior Developer',\n",
       " 'pipeline': <miniautogen.pipeline.pipeline.Pipeline at 0x13832d190>,\n",
       " 'status': 'ativo'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'storage_path': 'groupchat_data',\n",
       " 'db_path': 'groupchat_data/groupchat.db',\n",
       " 'storage': <miniautogen.storage.chatstorage.ChatStorage at 0x13832d410>,\n",
       " 'agentList': [<miniautogen.agent.agent.Agent at 0x13832d4d0>,\n",
       "  <miniautogen.agent.agent.Agent at 0x10df40710>],\n",
       " 'context_path': 'groupchat_data/context.json',\n",
       " 'context': {},\n",
       " 'custom_df': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'sender_id': 'user4',\n",
       "  'message': 'Que bom ouvir isso!',\n",
       "  'timestamp': Timestamp('2023-12-29 05:43:02.807385'),\n",
       "  'additional_info': None},\n",
       " {'id': 2,\n",
       "  'sender_id': 'user5',\n",
       "  'message': 'Vamos continuar conversando.',\n",
       "  'timestamp': Timestamp('2023-12-29 05:43:02.809925'),\n",
       "  'additional_info': {'topic': 'chat'}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.get_messages().to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
